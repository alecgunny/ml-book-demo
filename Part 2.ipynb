{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "X = df[dataset.feature_names].values\n",
    "y = dataset.target\n",
    "predictions = np.zeros_like(y)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for train_idx, valid_idx in kfold.split(X):\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "    preprocessor = StandardScaler().fit(X_train)\n",
    "    X_train, X_valid = preprocessor.transform(X_train), preprocessor.transform(X_valid)\n",
    "\n",
    "    # model = LogisticRegression()\n",
    "    model = LinearDiscriminantAnalysis()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions[valid_idx] = model.predict(X_valid)\n",
    "\n",
    "accuracy = (y == predictions).mean()\n",
    "wrong_rows = np.where(y != predictions)[0]\n",
    "\n",
    "print('Accuracy: {:0.2f}%'.format(100*accuracy))\n",
    "wrong_df = df.loc[wrong_rows]\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_product(arrays):\n",
    "    la = len(arrays)\n",
    "    dtype = np.result_type(*arrays)\n",
    "    arr = np.empty([len(a) for a in arrays] + [la], dtype=dtype)\n",
    "    for i, a in enumerate(np.ix_(*arrays)):\n",
    "        arr[...,i] = a\n",
    "    return arr.reshape(-1, la)\n",
    "\n",
    "num_samples = 25\n",
    "arrays = [np.linspace(X[:, i].min(), X[:, i].max(), num_samples) for i in range(len(dataset.feature_names))]\n",
    "grid = cartesian_product(arrays)\n",
    "\n",
    "grid_predictions0 = np.zeros((num_samples**4, 2))\n",
    "grid_predictions1 = grid_predictions0.copy()\n",
    "\n",
    "grid = (grid - X.mean(axis=0)) / X.std(axis=0)\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "predictions = np.zeros_like(y)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "for train_idx, valid_idx in kfold.split(X):\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "#     preprocessor = StandardScaler().fit(X_train)\n",
    "#     X_train, X_valid = preprocessor.transform(X_train), preprocessor.transform(X_valid)\n",
    "\n",
    "#     model = LogisticRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions[valid_idx] = model.predict(X_valid)\n",
    "#     grid_predictions += model.predict_proba(grid)\n",
    "\n",
    "    model0 = LinearDiscriminantAnalysis()\n",
    "    model0.fit(X_train, (y_train>0).astype('int'))\n",
    "    preds0 = model0.predict(X_valid)\n",
    "\n",
    "    X_train = X_train[y_train > 0]\n",
    "    y_train = y_train[y_train > 0]\n",
    "\n",
    "    model1 = LinearDiscriminantAnalysis()\n",
    "    model1.fit(X_train, y_train-1)\n",
    "    preds1 = model1.predict(X_valid)\n",
    "\n",
    "    # input_grid = preprocessor.transform(grid)\n",
    "    grid_predictions0 += model0.predict_proba(grid)\n",
    "    grid_predictions1 += model1.predict_proba(grid)\n",
    "\n",
    "    preds = preds0\n",
    "    preds[preds == 1] = preds1[preds == 1] + 1\n",
    "    predictions[valid_idx] = preds\n",
    "\n",
    "accuracy = (y == predictions).mean()\n",
    "wrong_rows = np.where(y != predictions)[0]\n",
    "\n",
    "print('Accuracy: {:0.2f}%'.format(100*accuracy))\n",
    "wrong_df = df.loc[wrong_rows]\n",
    "print(wrong_df)\n",
    "\n",
    "# grid_predictions = grid_predictions.argmax(axis=1)\n",
    "\n",
    "grid_predictions0 /= 5\n",
    "grid_predictions1 /= 5\n",
    "\n",
    "grid_predictions = grid_predictions0.argmax(axis=1)\n",
    "grid_predictions[grid_predictions == 1] = grid_predictions1[grid_predictions==1].argmax(axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = (grid - X.mean(axis=0)) / X.std(axis=0)\n",
    "# X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "eigvals, eigvecs = eig(X.T @ X)\n",
    "W = eigvecs[np.argsort(eigvals)[:2]].real\n",
    "X_2d = X @ W.T\n",
    "grid_transformed = grid @ W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "arrays = [np.linspace(X_2d[:, i].min(), X_2d[:, i].max(), num_samples) for i in range(2)]\n",
    "grid_2d = cartesian_product(arrays)\n",
    "\n",
    "k = 10\n",
    "predictions = []\n",
    "for sample in grid_2d:\n",
    "    distances = ((sample - grid_transformed)**2).sum(axis=1)\n",
    "    top_k = grid_predictions[np.argsort(distances)[-k:]]\n",
    "    predictions.append(mode(top_k).mode[0])\n",
    "\n",
    "image = np.array(predictions).reshape(num_samples, num_samples)\n",
    "p.image(\n",
    "    image=[image.T[::-1, ::-1]],\n",
    "    x=arrays[0][0],\n",
    "    y=arrays[1][0],\n",
    "    dw=arrays[0][-1]-arrays[0][0],\n",
    "    dh=arrays[1][-1]-arrays[1][0],\n",
    "    palette=palette,\n",
    "    global_alpha=0.25,\n",
    "    level=\"image\"\n",
    ")\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
